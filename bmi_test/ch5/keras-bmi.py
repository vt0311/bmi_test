from keras.models import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.callbacks import EarlyStopping
import pandas as pd, numpy as np

# BMI 데이터를 읽어 들이고 정규화하기 
csv = pd.read_csv("bmi.csv")

# 몸무게와 키 데이터
csv["weight"] /= 100
csv["height"] /= 200
X = csv[["weight", "height"]].as_matrix() 

# 레이블
bclass = {"thin":[1,0,0], "normal":[0,1,0], "fat":[0,0,1]}
y = np.empty((20000,3))
for i, v in enumerate(csv["label"]):
    y[i] = bclass[v]
    
# 훈련 전용 데이터와 테스트 전용 데이터로 나누기 
X_train, y_train = X[1:15001], y[1:15001]
X_test,  y_test  = X[15001:20001], y[15001:20001] 

# 모델 구조 정의하기 
model = Sequential()
model.add(Dense(512, input_shape=(2,)))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(3))
model.add(Activation('softmax'))

# 모델 구축하기 
model.compile(
    loss='categorical_crossentropy',
    optimizer="rmsprop",
    metrics=['accuracy'])

# 데이터 훈련하기 
hist = model.fit(
    X_train, y_train,
    batch_size=100, # batch_size란 : 뭔가를 하나 수정할 때 모든 데이터를 다시 처리하는 것은 낭비이므로, 훈련 데이터를 여러 개의 작은 배치로 나누어 매개변수를 수정하는데, 이떄의 작은 배치 사이즈를 말한다.
    nb_epoch=20,
    validation_split=0.1,
    callbacks=[EarlyStopping(monitor='val_loss', patience=2)], # EarlyStopping : 데이터의 정밀도에 문제가 발생했을 때 훈련을 중지하게 하는 역할. 
    verbose=1)

# 테스트 데이터로 평가하기 
score = model.evaluate(X_test, y_test)
print('loss=', score[0])
print('accuracy=', score[1])


# 결과 :
'''
(앞부분 생략)

  100/13500 [..............................] - ETA: 1s - loss: 0.2369 - acc: 0.9
000
  600/13500 [>.............................] - ETA: 1s - loss: 0.1873 - acc: 0.9
183
 1100/13500 [=>............................] - ETA: 1s - loss: 0.1336 - acc: 0.9
464
 1600/13500 [==>...........................] - ETA: 1s - loss: 0.1151 - acc: 0.9
569
 2100/13500 [===>..........................] - ETA: 1s - loss: 0.1218 - acc: 0.9
529
 2600/13500 [====>.........................] - ETA: 1s - loss: 0.1362 - acc: 0.9
450
 3100/13500 [=====>........................] - ETA: 1s - loss: 0.1298 - acc: 0.9
468
 3600/13500 [=======>......................] - ETA: 1s - loss: 0.1386 - acc: 0.9
433
 4100/13500 [========>.....................] - ETA: 1s - loss: 0.1301 - acc: 0.9
471
 4600/13500 [=========>....................] - ETA: 1s - loss: 0.1218 - acc: 0.9
511
 5100/13500 [==========>...................] - ETA: 0s - loss: 0.1231 - acc: 0.9
504
 5600/13500 [===========>..................] - ETA: 0s - loss: 0.1189 - acc: 0.9
527
 6100/13500 [============>.................] - ETA: 0s - loss: 0.1246 - acc: 0.9
498
 6600/13500 [=============>................] - ETA: 0s - loss: 0.1207 - acc: 0.9
512
 7100/13500 [==============>...............] - ETA: 0s - loss: 0.1168 - acc: 0.9
530
 7600/13500 [===============>..............] - ETA: 0s - loss: 0.1198 - acc: 0.9
505
 8100/13500 [=================>............] - ETA: 0s - loss: 0.1164 - acc: 0.9
520
 8400/13500 [=================>............] - ETA: 0s - loss: 0.1157 - acc: 0.9
524
 8700/13500 [==================>...........] - ETA: 0s - loss: 0.1189 - acc: 0.9
514
 9000/13500 [===================>..........] - ETA: 0s - loss: 0.1175 - acc: 0.9
521
 9300/13500 [===================>..........] - ETA: 0s - loss: 0.1162 - acc: 0.9
525
 9700/13500 [====================>.........] - ETA: 0s - loss: 0.1171 - acc: 0.9
512
10000/13500 [=====================>........] - ETA: 0s - loss: 0.1205 - acc: 0.9
495
10300/13500 [=====================>........] - ETA: 0s - loss: 0.1219 - acc: 0.9
484
10700/13500 [======================>.......] - ETA: 0s - loss: 0.1201 - acc: 0.9
493
11200/13500 [=======================>......] - ETA: 0s - loss: 0.1186 - acc: 0.9
497
11700/13500 [=========================>....] - ETA: 0s - loss: 0.1174 - acc: 0.9
501
12200/13500 [==========================>...] - ETA: 0s - loss: 0.1177 - acc: 0.9
498
12700/13500 [===========================>..] - ETA: 0s - loss: 0.1178 - acc: 0.9
493
13200/13500 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9
500
13500/13500 [==============================] - 2s 129us/step - loss: 0.1163 - ac
c: 0.9499 - val_loss: 0.3832 - val_acc: 0.8573

  32/4999 [..............................] - ETA: 0s
1024/4999 [=====>........................] - ETA: 0s
2080/4999 [===========>..................] - ETA: 0s
3168/4999 [==================>...........] - ETA: 0s
4192/4999 [========================>.....] - ETA: 0s
4999/4999 [==============================] - 0s 48us/step
loss= 0.402519756256
accuracy= 0.847169433923
'''